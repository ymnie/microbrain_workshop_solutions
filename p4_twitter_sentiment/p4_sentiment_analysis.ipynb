{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-01-15T09:39:57.309238Z","iopub.execute_input":"2023-01-15T09:39:57.310401Z","iopub.status.idle":"2023-01-15T09:39:57.34903Z","shell.execute_reply.started":"2023-01-15T09:39:57.310281Z","shell.execute_reply":"2023-01-15T09:39:57.348134Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Loading Libraries","metadata":{}},{"cell_type":"markdown","source":"Using Hugging face transformers","metadata":{}},{"cell_type":"code","source":"import pandas as pd, numpy as np\nimport tensorflow as tf\nimport tensorflow.keras.backend as K\nfrom sklearn.model_selection import StratifiedKFold\nfrom transformers import *\nimport tokenizers\nprint('TF version',tokenizers.__version__)\n","metadata":{"execution":{"iopub.status.busy":"2023-01-06T11:16:06.408573Z","iopub.execute_input":"2023-01-06T11:16:06.408951Z","iopub.status.idle":"2023-01-06T11:16:40.504903Z","shell.execute_reply.started":"2023-01-06T11:16:06.408914Z","shell.execute_reply":"2023-01-06T11:16:40.502637Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"MAX_LEN = 96\nPATH = '../input/tf-roberta/'\ntokenizer = tokenizers.ByteLevelBPETokenizer(\n    vocab = PATH+'vocab-roberta-base.json', \n    merges = PATH+'merges-roberta-base.txt', \n    lowercase = True,\n    add_prefix_space = True\n)\nsentiment_id = {'positive': 1313, 'negative': 2430, 'neutral': 7974}\ntrain = pd.read_csv('../input/tweet-sentiment-extraction/train.csv').fillna('')\ntrain.head()","metadata":{"execution":{"iopub.status.busy":"2023-01-06T11:17:25.567704Z","iopub.execute_input":"2023-01-06T11:17:25.570339Z","iopub.status.idle":"2023-01-06T11:17:25.866892Z","shell.execute_reply.started":"2023-01-06T11:17:25.570297Z","shell.execute_reply":"2023-01-06T11:17:25.865955Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train Data","metadata":{}},{"cell_type":"code","source":"ct = train.shape[0]\ninput_ids = np.ones((ct,MAX_LEN),dtype = 'int32')\nattention_mask = np.zeros((ct,MAX_LEN),dtype = 'int32')\ntoken_type_ids = np.zeros((ct,MAX_LEN),dtype = 'int32')\nstart_tokens = np.zeros((ct,MAX_LEN),dtype = 'int32')\nend_tokens = np.zeros((ct,MAX_LEN),dtype = 'int32')\n\nfor k in range(train.shape[0]):\n    \n    # finding overlaps\n    text1 = \" \"+\" \".join(train.loc[k,'text'].split())\n    text2 = \" \".join(train.loc[k,'selected_text'].split())\n    idx = text1.find(text2)\n    chars = np.zeros((len(text1)))\n    chars[idx:idx+len(text2)] = 1\n    if text1[idx-1]==' ': chars[idx-1] = 1 \n    enc = tokenizer.encode(text1) \n        \n    # ID_OFFSETS\n    offsets = []; idx=0\n    for t in enc.ids:\n        w = tokenizer.decode([t])\n        offsets.append((idx,idx+len(w)))\n        idx += len(w)\n    \n    # start-end tokens\n    toks = []\n    for i,(a,b) in enumerate(offsets):\n        sm = np.sum(chars[a:b])\n        if sm>0: toks.append(i) \n        \n    s_tok = sentiment_id[train.loc[k,'sentiment']]\n    input_ids[k,:len(enc.ids)+5] = [0] + enc.ids + [2,2] + [s_tok] + [2]\n    attention_mask[k,:len(enc.ids)+5] = 1\n    if len(toks)>0:\n        start_tokens[k,toks[0]+1] = 1\n        end_tokens[k,toks[-1]+1] = 1","metadata":{"execution":{"iopub.status.busy":"2023-01-06T11:17:27.607052Z","iopub.execute_input":"2023-01-06T11:17:27.607522Z","iopub.status.idle":"2023-01-06T11:17:35.387615Z","shell.execute_reply.started":"2023-01-06T11:17:27.60748Z","shell.execute_reply":"2023-01-06T11:17:35.386542Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Test Data","metadata":{}},{"cell_type":"markdown","source":"Tokenizing test data","metadata":{}},{"cell_type":"code","source":"test = pd.read_csv('../input/tweet-sentiment-extraction/test.csv').fillna('')\n\nct = test.shape[0]\ninput_ids_t = np.ones((ct,MAX_LEN),dtype='int32')\nattention_mask_t = np.zeros((ct,MAX_LEN),dtype='int32')\ntoken_type_ids_t = np.zeros((ct,MAX_LEN),dtype='int32')\n\nfor k in range(test.shape[0]):\n        \n    # INPUT_IDS\n    text1 = \" \"+\" \".join(test.loc[k,'text'].split())\n    enc = tokenizer.encode(text1)                \n    s_tok = sentiment_id[test.loc[k,'sentiment']]\n    input_ids_t[k,:len(enc.ids)+5] = [0] + enc.ids + [2,2] + [s_tok] + [2]\n    attention_mask_t[k,:len(enc.ids)+5] = 1","metadata":{"execution":{"iopub.status.busy":"2023-01-06T11:17:38.837603Z","iopub.execute_input":"2023-01-06T11:17:38.837989Z","iopub.status.idle":"2023-01-06T11:17:39.30992Z","shell.execute_reply.started":"2023-01-06T11:17:38.837957Z","shell.execute_reply":"2023-01-06T11:17:39.308964Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# RoBERTa Model","metadata":{}},{"cell_type":"code","source":"def build_model():\n    ids = tf.keras.layers.Input((MAX_LEN,), dtype = tf.int32)\n    att = tf.keras.layers.Input((MAX_LEN,), dtype = tf.int32)\n    tok = tf.keras.layers.Input((MAX_LEN,), dtype = tf.int32)\n\n    config = RobertaConfig.from_pretrained(PATH+'config-roberta-base.json')\n    bert_model = TFRobertaModel.from_pretrained(PATH+'pretrained-roberta-base.h5',config = config)\n    x = bert_model(ids,attention_mask=att,token_type_ids=tok)\n    \n    x1 = tf.keras.layers.Dropout(0.1)(x[0]) \n    x1 = tf.keras.layers.Conv1D(1,1)(x1)\n    x1 = tf.keras.layers.Flatten()(x1)\n    x1 = tf.keras.layers.Activation('softmax')(x1)\n    \n    x2 = tf.keras.layers.Dropout(0.1)(x[0]) \n    x2 = tf.keras.layers.Conv1D(1,1)(x2)\n    x2 = tf.keras.layers.Flatten()(x2)\n    x2 = tf.keras.layers.Activation('softmax')(x2)\n\n    model = tf.keras.models.Model(inputs=[ids, att, tok], outputs = [x1,x2])\n    optimizer = tf.keras.optimizers.Adam(learning_rate = 3e-5)\n    model.compile(loss = 'categorical_crossentropy', optimizer = optimizer)\n\n    return model","metadata":{"execution":{"iopub.status.busy":"2023-01-06T11:17:42.181787Z","iopub.execute_input":"2023-01-06T11:17:42.182151Z","iopub.status.idle":"2023-01-06T11:17:42.194274Z","shell.execute_reply.started":"2023-01-06T11:17:42.182119Z","shell.execute_reply":"2023-01-06T11:17:42.193409Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Jaccard score","metadata":{}},{"cell_type":"code","source":"#func\ndef jaccard(str1, str2): \n    doc1 = set(str1.lower().split()) \n    doc2 = set(str2.lower().split())\n    if (len(doc1)==0) & (len(doc2)==0): return 0.5\n    c = doc1.intersection(doc2)\n    return float(len(c)) / (len(doc1) + len(doc2) - len(c))","metadata":{"execution":{"iopub.status.busy":"2023-01-06T11:17:47.106941Z","iopub.execute_input":"2023-01-06T11:17:47.107376Z","iopub.status.idle":"2023-01-06T11:17:47.115007Z","shell.execute_reply.started":"2023-01-06T11:17:47.107341Z","shell.execute_reply":"2023-01-06T11:17:47.113665Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training Model","metadata":{}},{"cell_type":"code","source":"jac = []; VER = 'v0'; DISPLAY = 1 # USE display=1 foe INTERACTIVE\noof_start = np.zeros((input_ids.shape[0], MAX_LEN))\noof_end = np.zeros((input_ids.shape[0], MAX_LEN))\npreds_start = np.zeros((input_ids_t.shape[0], MAX_LEN))\npreds_end = np.zeros((input_ids_t.shape[0], MAX_LEN))\n\nskf = StratifiedKFold(n_splits = 5,shuffle = True,random_state = 777)\nfor fold,(idxT,idxV) in enumerate(skf.split(input_ids,train.sentiment.values)):\n\n    print('*'*25)\n    print('*** FOLD %i - '%(fold+1))\n    print('*'*25)\n    \n    K.clear_session()\n    model = build_model()\n        \n    sv = tf.keras.callbacks.ModelCheckpoint(\n        '%s-roberta-%i.h5'%(VER,fold), monitor = 'val_loss', verbose = 1, save_best_only = True,\n        save_weights_only = True, mode = 'auto', save_freq = 'epoch')\n        \n    model.fit([input_ids[idxT,], attention_mask[idxT,], token_type_ids[idxT,]], [start_tokens[idxT,], end_tokens[idxT,]], \n        epochs = 3, batch_size = 32, verbose = DISPLAY, callbacks = [sv],\n        validation_data = ([input_ids[idxV,],attention_mask[idxV,],token_type_ids[idxV,]], \n        [start_tokens[idxV,], end_tokens[idxV,]]))\n    \n    print('Loading the model...')\n    model.load_weights('%s-roberta-%i.h5'%(VER,fold))\n    \n    print('Predicting a OOF...')\n    oof_start[idxV,],oof_end[idxV,] = model.predict([input_ids[idxV,],attention_mask[idxV,],token_type_ids[idxV,]],verbose=DISPLAY)\n    \n    print('Predicting Test data...')\n    preds = model.predict([input_ids_t,attention_mask_t,token_type_ids_t],verbose = DISPLAY)\n    preds_start += preds[0]/skf.n_splits\n    preds_end += preds[1]/skf.n_splits\n    \n    # DISPLAY FOLD JACCARD\n    all = []\n    for k in idxV:\n        a = np.argmax(oof_start[k,])\n        b = np.argmax(oof_end[k,])\n        if a>b: \n            st = train.loc[k,'text'] # imporving cb/lb\n        else:\n            text1 = \" \"+\" \".join(train.loc[k,'text'].split())\n            enc = tokenizer.encode(text1)\n            st = tokenizer.decode(enc.ids[a-1:b])\n        all.append(jaccard(st,train.loc[k,'selected_text']))\n    jac.append(np.mean(all))\n    print('>>>> FOLD %i Jaccard ='%(fold+1), np.mean(all))\n    print()","metadata":{"execution":{"iopub.status.busy":"2023-01-06T11:17:56.431581Z","iopub.execute_input":"2023-01-06T11:17:56.431966Z"},"trusted":true},"execution_count":null,"outputs":[]}]}